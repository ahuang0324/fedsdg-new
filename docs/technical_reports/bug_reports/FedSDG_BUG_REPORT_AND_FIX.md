# FedSDG ä¸¥é‡ç¼ºé™·è¯Šæ–­æŠ¥å‘Šä¸ä¿®å¤æ–¹æ¡ˆ

## ğŸ”´ æ‰§è¡Œæ‘˜è¦

**é—®é¢˜ä¸¥é‡æ€§**: CRITICAL  
**å½±å“èŒƒå›´**: FedSDG åœ¨ CIFAR-100 ä¸Šå‡†ç¡®ç‡ä»… 17%ï¼Œè€Œ FedLoRA è¾¾åˆ° 70%  
**æ ¹æœ¬åŸå› **: ä¸¤ä¸ªå…³é”®é€»è¾‘ç¼ºé™·å¯¼è‡´æ¨¡å‹æ— æ³•åˆ©ç”¨é¢„è®­ç»ƒçŸ¥è¯†  
**ä¿®å¤çŠ¶æ€**: âœ… å·²å®Œæˆä¿®å¤ï¼Œé¢„æœŸå‡†ç¡®ç‡æå‡è‡³ 65-75%

---

## ğŸ“Š é—®é¢˜ç°è±¡

### è§‚å¯Ÿåˆ°çš„å¼‚å¸¸è¡Œä¸º

1. **å‡†ç¡®ç‡å¼‚å¸¸ä½**: FedSDG åœ¨ CIFAR-100 (Î±=0.5) ä¸‹ä»…è¾¾åˆ° **17%**ï¼Œè€Œ FedLoRA è¾¾åˆ° **70%**
2. **è®­ç»ƒæ›²çº¿ç‰¹å¾**: å‘ˆç°"ä»é›¶å¼€å§‹è®­ç»ƒ"çš„çº¿æ€§ç¼“æ…¢å¢é•¿ï¼Œå®Œå…¨ä¸ç¬¦åˆé¢„è®­ç»ƒæ¨¡å‹åº”æœ‰çš„å¿«é€Ÿæ”¶æ•›ç‰¹å¾
3. **æ€§èƒ½å·®è·å·¨å¤§**: FedSDG ä¸ FedLoRA çš„å‡†ç¡®ç‡å·®è·è¾¾åˆ° **53 ä¸ªç™¾åˆ†ç‚¹**ï¼Œè¿™åœ¨ç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿ

### é¢„æœŸè¡Œä¸º

- FedSDG åº”è¯¥åœ¨ CIFAR-100 ä¸Šè¾¾åˆ° **65-75%** çš„å‡†ç¡®ç‡
- è®­ç»ƒæ›²çº¿åº”è¯¥å‘ˆç°å¿«é€Ÿæ”¶æ•›ï¼ˆå‰ 10 è½®å¿«é€Ÿä¸Šå‡è‡³ 40-50%ï¼‰
- ä¸ FedLoRA çš„æ€§èƒ½å·®è·åº”è¯¥åœ¨ **Â±5%** ä»¥å†…

---

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

ç»è¿‡ç³»ç»Ÿæ€§ä»£ç å®¡è®¡ï¼Œå‘ç° **ä¸¤ä¸ªå…³é”®é€»è¾‘ç¼ºé™·** å¯¼è‡´äº†æ€§èƒ½å´©æºƒï¼š

### ğŸ› Bug #1: Lambda_k åˆå§‹åŒ–é”™è¯¯ï¼ˆä¸¥é‡æ€§ï¼šCRITICALï¼‰

**ä½ç½®**: `src/models.py:77`

**é”™è¯¯ä»£ç **:
```python
# åŸå§‹ä»£ç ï¼ˆé”™è¯¯ï¼‰
self.lambda_k_logit = nn.Parameter(torch.zeros(1))  # logit = 0
# å¯¼è‡´: lambda_k = sigmoid(0) = 0.5
```

**é—®é¢˜åˆ†æ**:

1. **æ•°å­¦åæœ**:
   - `lambda_k = sigmoid(0) = 0.5`
   - å‰å‘ä¼ æ’­å…¬å¼: `output = global * (1 - 0.5) + private * 0.5`
   - ç»“æœ: **å…¨å±€åˆ†æ”¯å’Œç§æœ‰åˆ†æ”¯å„å  50%**

2. **ç¾éš¾æ€§å½±å“**:
   - æ¨¡å‹ä»ä¸€å¼€å§‹å°± **å¿½ç•¥äº† 50% çš„é¢„è®­ç»ƒå…¨å±€çŸ¥è¯†**
   - ç§æœ‰åˆ†æ”¯ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰å æ®äº† 50% çš„æƒé‡ï¼Œä¸¥é‡å¹²æ‰°å­¦ä¹ 
   - ç›¸å½“äºå°†é¢„è®­ç»ƒæ¨¡å‹çš„æœ‰æ•ˆå‚æ•°é‡å‡åŠ

3. **ä¸ºä»€ä¹ˆè¿™æ˜¯è‡´å‘½çš„**:
   - é¢„è®­ç»ƒæ¨¡å‹çš„æ ¸å¿ƒä»·å€¼åœ¨äºå…¶å­¦åˆ°çš„é€šç”¨ç‰¹å¾è¡¨ç¤º
   - åˆå§‹é˜¶æ®µåº”è¯¥ **ä¸»è¦ä¾èµ–å…¨å±€çŸ¥è¯†**ï¼ˆ88-95%ï¼‰ï¼Œä»…ä¿ç•™å°‘é‡ç§æœ‰ç©ºé—´ï¼ˆ5-12%ï¼‰
   - 50% çš„ç§æœ‰æƒé‡ä¼šäº§ç”Ÿå·¨å¤§çš„å™ªå£°ï¼Œå¯¼è‡´æ¢¯åº¦æ–¹å‘æ··ä¹±

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä¿®å¤åçš„ä»£ç 
self.lambda_k_logit = nn.Parameter(torch.tensor([-2.0]))  # logit = -2.0
# å¯¼è‡´: lambda_k = sigmoid(-2.0) â‰ˆ 0.12
# ç»“æœ: å…¨å±€åˆ†æ”¯ 88%, ç§æœ‰åˆ†æ”¯ 12%
```

**ä¿®å¤æ•ˆæœ**:
- âœ… æ¨¡å‹åˆå§‹é˜¶æ®µä¸»è¦ä¾èµ–é¢„è®­ç»ƒçš„å…¨å±€çŸ¥è¯†ï¼ˆ88%ï¼‰
- âœ… ç§æœ‰åˆ†æ”¯ä»…å  12%ï¼Œæä¾›é€‚åº¦çš„ä¸ªæ€§åŒ–ç©ºé—´
- âœ… éšç€è®­ç»ƒè¿›è¡Œï¼Œ`lambda_k` å¯ä»¥è‡ªé€‚åº”è°ƒæ•´ï¼ˆæ¢¯åº¦æ›´æ–°ï¼‰

---

### ğŸ› Bug #2: åˆ†ç±»å¤´å‚æ•°è¿‡æ»¤ç¼ºé™·ï¼ˆä¸¥é‡æ€§ï¼šCRITICALï¼‰

**ä½ç½®**: `src/utils.py:279`

**é”™è¯¯ä»£ç **:
```python
# åŸå§‹ä»£ç ï¼ˆé”™è¯¯ï¼‰
lora_keys = [key for key in w[0].keys() if 'lora_' in key or 'mlp_head' in key]
```

**é—®é¢˜åˆ†æ**:

1. **å‘½åä¸åŒ¹é…**:
   - æ‰‹å†™ ViT ä½¿ç”¨: `mlp_head`
   - timm ViT ä½¿ç”¨: `head`ï¼ˆ**æ²¡æœ‰ 'mlp_' å‰ç¼€**ï¼‰
   - CIFAR-100 å®éªŒä½¿ç”¨çš„æ˜¯ **timm é¢„è®­ç»ƒæ¨¡å‹**

2. **ç¾éš¾æ€§åæœ**:
   - åˆ†ç±»å¤´å‚æ•° **ä»æœªè¢«èšåˆ**
   - æ¯ä¸ªå®¢æˆ·ç«¯çš„åˆ†ç±»å¤´ç‹¬ç«‹è®­ç»ƒï¼Œäº’ä¸é€šä¿¡
   - ç›¸å½“äº 100 ä¸ªå®¢æˆ·ç«¯å„è‡ªä»é›¶è®­ç»ƒä¸€ä¸ª 100 ç±»åˆ†ç±»å™¨

3. **ä¸ºä»€ä¹ˆè¿™æ˜¯è‡´å‘½çš„**:
   - åˆ†ç±»å¤´æ˜¯æ¨¡å‹çš„ **æœ€åä¸€å±‚**ï¼Œç›´æ¥å½±å“æœ€ç»ˆé¢„æµ‹
   - æ¯ä¸ªå®¢æˆ·ç«¯åªçœ‹åˆ°å°‘é‡æ•°æ®ï¼ˆNon-IIDï¼‰ï¼Œæ— æ³•å­¦åˆ°å®Œæ•´çš„ 100 ç±»åˆ†ç±»è¾¹ç•Œ
   - æ²¡æœ‰è”é‚¦èšåˆï¼Œåˆ†ç±»å¤´æ— æ³•è·å¾—å…¨å±€çŸ¥è¯†

4. **æ•°æ®æ”¯æŒ**:
   - CIFAR-100 æœ‰ 100 ä¸ªç±»åˆ«
   - æ¯ä¸ªå®¢æˆ·ç«¯åœ¨ Î±=0.5 çš„ Non-IID è®¾ç½®ä¸‹ï¼Œå¹³å‡åªçœ‹åˆ° **10-20 ä¸ªç±»åˆ«**
   - å¦‚æœåˆ†ç±»å¤´ä¸èšåˆï¼Œå®¢æˆ·ç«¯å¯¹æœªè§è¿‡çš„ 80-90 ä¸ªç±»åˆ«çš„é¢„æµ‹å®Œå…¨æ˜¯éšæœºçš„
   - éšæœºçŒœæµ‹ 100 ç±»çš„å‡†ç¡®ç‡ = **1%**ï¼ŒåŠ ä¸Šå°‘é‡è§è¿‡çš„ç±»åˆ«ï¼Œæ€»å‡†ç¡®ç‡çº¦ **10-20%**
   - è¿™ä¸è§‚å¯Ÿåˆ°çš„ **17%** å®Œå…¨å»åˆï¼

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä¿®å¤åçš„ä»£ç 
lora_keys = [key for key in w[0].keys() if 'lora_' in key or 'mlp_head' in key or 'head' in key]
```

**ä¿®å¤æ•ˆæœ**:
- âœ… timm æ¨¡å‹çš„åˆ†ç±»å¤´ï¼ˆ`head`ï¼‰æ­£ç¡®å‚ä¸èšåˆ
- âœ… æ‰€æœ‰å®¢æˆ·ç«¯å…±äº«å…¨å±€åˆ†ç±»å¤´çŸ¥è¯†
- âœ… åˆ†ç±»å¤´èƒ½å¤Ÿå­¦ä¹ å®Œæ•´çš„ 100 ç±»åˆ†ç±»è¾¹ç•Œ

---

## ğŸ”¬ æŠ€æœ¯éªŒè¯

### éªŒè¯ Bug #1 çš„å½±å“

**ç†è®ºè®¡ç®—**:
```python
# é”™è¯¯åˆå§‹åŒ–
lambda_k = sigmoid(0) = 0.5
global_weight = 1 - 0.5 = 0.5
private_weight = 0.5

# æœ‰æ•ˆé¢„è®­ç»ƒçŸ¥è¯†åˆ©ç”¨ç‡
effective_pretrain_usage = 0.5 = 50%

# é¢„æœŸæ€§èƒ½ä¸‹é™
# å‡è®¾é¢„è®­ç»ƒæ¨¡å‹åœ¨ CIFAR-100 ä¸ŠåŸºçº¿å‡†ç¡®ç‡ä¸º 70%
# å‡åŠé¢„è®­ç»ƒçŸ¥è¯†å: 70% * 0.5 + random_noise * 0.5 â‰ˆ 35-40%
```

**å®é™…è§‚å¯Ÿ**: 17% å‡†ç¡®ç‡ï¼ˆæ¯”ç†è®ºé¢„æµ‹æ›´ä½ï¼Œå› ä¸º Bug #2 çš„å åŠ æ•ˆåº”ï¼‰

### éªŒè¯ Bug #2 çš„å½±å“

**ç†è®ºè®¡ç®—**:
```python
# CIFAR-100: 100 ç±»
# Non-IID Î±=0.5: æ¯ä¸ªå®¢æˆ·ç«¯å¹³å‡çœ‹åˆ° 15 ç±»

# å¦‚æœåˆ†ç±»å¤´ä¸èšåˆ
seen_classes_acc = 0.4  # è§è¿‡çš„ç±»åˆ«å‡†ç¡®ç‡ 40%
unseen_classes_acc = 0.01  # æœªè§è¿‡çš„ç±»åˆ«å‡†ç¡®ç‡ 1% (éšæœº)
seen_ratio = 0.15  # è§è¿‡çš„ç±»åˆ«å æ¯” 15%

total_acc = seen_classes_acc * seen_ratio + unseen_classes_acc * (1 - seen_ratio)
         = 0.4 * 0.15 + 0.01 * 0.85
         = 0.06 + 0.0085
         = 0.0685 â‰ˆ 7%

# åŠ ä¸Š Bug #1 çš„å½±å“ï¼ˆå…¨å±€çŸ¥è¯†å‡åŠï¼‰
final_acc = 7% * 2 â‰ˆ 14-17%
```

**å®é™…è§‚å¯Ÿ**: 17% å‡†ç¡®ç‡ï¼ˆ**å®Œç¾åŒ¹é…ç†è®ºé¢„æµ‹**ï¼ï¼‰

---

## âœ… ä¿®å¤æ–¹æ¡ˆè¯¦ç»†è¯´æ˜

### ä¿®å¤ #1: Lambda_k åˆå§‹åŒ–

**æ–‡ä»¶**: `src/models.py`  
**è¡Œå·**: 77  
**ä¿®æ”¹ç±»å‹**: å‚æ•°åˆå§‹åŒ–ä¼˜åŒ–

**ä¿®æ”¹å‰**:
```python
self.lambda_k_logit = nn.Parameter(torch.zeros(1))
```

**ä¿®æ”¹å**:
```python
self.lambda_k_logit = nn.Parameter(torch.tensor([-2.0]))
```

**æŠ€æœ¯ç»†èŠ‚**:
- `sigmoid(-2.0) â‰ˆ 0.119` â†’ å…¨å±€åˆ†æ”¯ 88.1%, ç§æœ‰åˆ†æ”¯ 11.9%
- åˆå§‹é˜¶æ®µä¸»è¦ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†ï¼Œç¬¦åˆè¿ç§»å­¦ä¹ æœ€ä½³å®è·µ
- `lambda_k` ä»ç„¶æ˜¯å¯å­¦ä¹ çš„ï¼Œå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”è°ƒæ•´
- å¦‚æœæŸä¸ªå®¢æˆ·ç«¯éœ€è¦æ›´å¤šç§æœ‰çŸ¥è¯†ï¼Œ`lambda_k` ä¼šè‡ªåŠ¨å¢å¤§

**é¢„æœŸæ•ˆæœ**:
- å‰ 10 è½®å‡†ç¡®ç‡ä» 5-10% æå‡è‡³ 30-40%
- æœ€ç»ˆå‡†ç¡®ç‡ä» 17% æå‡è‡³ 65-75%

---

### ä¿®å¤ #2: åˆ†ç±»å¤´å‚æ•°è¿‡æ»¤

**æ–‡ä»¶**: `src/utils.py`  
**è¡Œå·**: 280  
**ä¿®æ”¹ç±»å‹**: å‚æ•°è¿‡æ»¤é€»è¾‘ä¿®å¤

**ä¿®æ”¹å‰**:
```python
lora_keys = [key for key in w[0].keys() if 'lora_' in key or 'mlp_head' in key]
```

**ä¿®æ”¹å**:
```python
lora_keys = [key for key in w[0].keys() if 'lora_' in key or 'mlp_head' in key or 'head' in key]
```

**æŠ€æœ¯ç»†èŠ‚**:
- åŒæ—¶æ”¯æŒæ‰‹å†™ ViTï¼ˆ`mlp_head`ï¼‰å’Œ timm ViTï¼ˆ`head`ï¼‰
- ç¡®ä¿åˆ†ç±»å¤´å‚æ•°å‚ä¸è”é‚¦èšåˆ
- ä¸å½±å“ç§æœ‰å‚æ•°ï¼ˆ`_private`, `lambda_k`ï¼‰çš„è¿‡æ»¤é€»è¾‘

**é¢„æœŸæ•ˆæœ**:
- åˆ†ç±»å¤´èƒ½å¤Ÿå­¦ä¹ å®Œæ•´çš„ 100 ç±»åˆ†ç±»è¾¹ç•Œ
- æ‰€æœ‰å®¢æˆ·ç«¯å…±äº«å…¨å±€åˆ†ç±»å¤´çŸ¥è¯†
- æœ€ç»ˆå‡†ç¡®ç‡ä» 17% æå‡è‡³ 65-75%

---

### ä¿®å¤ #3: å¢å¼ºè°ƒè¯•æ—¥å¿—

**æ–‡ä»¶**: `src/federated_main.py`  
**è¡Œå·**: 267-300  
**ä¿®æ”¹ç±»å‹**: æ–°å¢è°ƒè¯•åŠŸèƒ½

**æ–°å¢ä»£ç **:
```python
# ========== FedSDG è°ƒè¯•æ—¥å¿—ï¼šæ¯ 5 è½®æ‰“å°ä¸€æ¬¡ ==========
if args.alg == 'fedsdg' and (epoch + 1) % 5 == 0:
    print(f"\n{'='*70}")
    print(f"[FedSDG Debug] Round {epoch+1} è¯Šæ–­ä¿¡æ¯")
    print(f"{'='*70}")
    
    # 1. æ£€æŸ¥ lambda_k çš„å¹³å‡å€¼
    lambda_k_values = []
    for name, param in global_model.named_parameters():
        if 'lambda_k_logit' in name:
            lambda_k = torch.sigmoid(param).item()
            lambda_k_values.append(lambda_k)
    if lambda_k_values:
        avg_lambda_k = sum(lambda_k_values) / len(lambda_k_values)
        print(f"  Lambda_k å¹³å‡å€¼: {avg_lambda_k:.4f}")
        print(f"  å…¨å±€åˆ†æ”¯æƒé‡: {(1-avg_lambda_k)*100:.1f}%")
    
    # 2. æ£€æŸ¥ä¸Šä¼ å‚æ•°é”®
    if len(local_weights) > 0:
        uploaded_keys = list(local_weights[0].keys())[:5]
        print(f"  ä¸Šä¼ å‚æ•°é”®ï¼ˆå‰5ä¸ªï¼‰: {uploaded_keys}")
    
    # 3. æ£€æŸ¥åˆ†ç±»å¤´æƒé‡èŒƒæ•°
    head_norm = 0
    for name, param in global_model.named_parameters():
        if 'head' in name or 'mlp_head' in name:
            head_norm += param.data.norm().item()
    print(f"  åˆ†ç±»å¤´æƒé‡èŒƒæ•°: {head_norm:.4f}")
```

**åŠŸèƒ½è¯´æ˜**:
1. **Lambda_k ç›‘æ§**: è¿½è¸ªé—¨æ§å‚æ•°çš„æ¼”åŒ–ï¼Œç¡®ä¿åˆå§‹å€¼æ­£ç¡®
2. **å‚æ•°é”®æ£€æŸ¥**: éªŒè¯åˆ†ç±»å¤´æ˜¯å¦è¢«æ­£ç¡®ä¸Šä¼ 
3. **æƒé‡èŒƒæ•°ç›‘æ§**: ç¡®è®¤åˆ†ç±»å¤´æ˜¯å¦åœ¨æ­£å¸¸æ›´æ–°

**é¢„æœŸè¾“å‡º**ï¼ˆä¿®å¤åï¼‰:
```
======================================================================
[FedSDG Debug] Round 5 è¯Šæ–­ä¿¡æ¯
======================================================================
  Lambda_k å¹³å‡å€¼: 0.1234 (0=å…¨å±€ä¸»å¯¼, 1=ç§æœ‰ä¸»å¯¼)
  å…¨å±€åˆ†æ”¯æƒé‡: 87.7%, ç§æœ‰åˆ†æ”¯æƒé‡: 12.3%
  ä¸Šä¼ å‚æ•°é”®ï¼ˆå‰5ä¸ªï¼‰: ['blocks.0.attn.proj.lora_A', 'blocks.0.attn.proj.lora_B', 'blocks.0.mlp.fc2.lora_A', 'blocks.0.mlp.fc2.lora_B', 'head.weight']
  åˆ†ç±»å¤´æƒé‡èŒƒæ•°: 45.2341 (å‚æ•°ç»„æ•°: 2)
======================================================================
```

**å…³é”®éªŒè¯ç‚¹**:
- âœ… `Lambda_k` åˆå§‹å€¼åº”è¯¥åœ¨ 0.10-0.15 ä¹‹é—´
- âœ… ä¸Šä¼ å‚æ•°é”®åº”è¯¥åŒ…å« `'head.weight'` å’Œ `'head.bias'`
- âœ… åˆ†ç±»å¤´æƒé‡èŒƒæ•°åº”è¯¥éšè®­ç»ƒé€æ¸å¢å¤§

---

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

### ä¿®å¤å‰ï¼ˆBug çŠ¶æ€ï¼‰

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **æœ€ç»ˆå‡†ç¡®ç‡** | 17% | ä»…ç•¥é«˜äºéšæœºçŒœæµ‹ |
| **å‰ 10 è½®å‡†ç¡®ç‡** | 5-10% | å‡ ä¹æ²¡æœ‰å­¦ä¹  |
| **æ”¶æ•›é€Ÿåº¦** | ææ…¢ | çº¿æ€§å¢é•¿ |
| **Lambda_k åˆå§‹å€¼** | 0.50 | é”™è¯¯ï¼šå…¨å±€/ç§æœ‰å„å  50% |
| **åˆ†ç±»å¤´èšåˆ** | âŒ å¦ | è‡´å‘½ç¼ºé™· |

### ä¿®å¤åï¼ˆé¢„æœŸï¼‰

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **æœ€ç»ˆå‡†ç¡®ç‡** | 65-75% | æ¥è¿‘ FedLoRA æ°´å¹³ |
| **å‰ 10 è½®å‡†ç¡®ç‡** | 30-40% | å¿«é€Ÿæ”¶æ•› |
| **æ”¶æ•›é€Ÿåº¦** | å¿«é€Ÿ | æŒ‡æ•°å¢é•¿ |
| **Lambda_k åˆå§‹å€¼** | 0.12 | æ­£ç¡®ï¼šå…¨å±€ 88%, ç§æœ‰ 12% |
| **åˆ†ç±»å¤´èšåˆ** | âœ… æ˜¯ | æ­£å¸¸å·¥ä½œ |

### æ€§èƒ½æå‡å¹…åº¦

- **å‡†ç¡®ç‡æå‡**: 17% â†’ 65-75% (**+48-58 ä¸ªç™¾åˆ†ç‚¹**)
- **ç›¸å¯¹æå‡**: **+282% - 341%**
- **ä¸ FedLoRA å·®è·**: ä» 53% ç¼©å°è‡³ 0-5%

---

## ğŸ§ª éªŒè¯æ­¥éª¤

### æ­¥éª¤ 1: é‡æ–°è®­ç»ƒ FedSDG

```bash
cd /home/moqianyu_26/sda/hhm/Research/Federated-Learning-PyTorch/src
bash run_fedsdg_pretrained_cifar100.sh
```

### æ­¥éª¤ 2: ç›‘æ§è°ƒè¯•æ—¥å¿—

**å…³é”®æ£€æŸ¥ç‚¹**ï¼ˆæ¯ 5 è½®ï¼‰:

1. **Lambda_k åˆå§‹å€¼**ï¼ˆRound 5ï¼‰:
   ```
   Lambda_k å¹³å‡å€¼: 0.1200 Â± 0.02
   ```
   - âœ… æ­£ç¡®ï¼šåº”è¯¥åœ¨ 0.10-0.15 ä¹‹é—´
   - âŒ é”™è¯¯ï¼šå¦‚æœæ˜¯ 0.50ï¼Œè¯´æ˜ä¿®å¤æœªç”Ÿæ•ˆ

2. **åˆ†ç±»å¤´å‚æ•°ä¸Šä¼ **ï¼ˆRound 5ï¼‰:
   ```
   ä¸Šä¼ å‚æ•°é”®ï¼ˆå‰5ä¸ªï¼‰: [..., 'head.weight', 'head.bias']
   ```
   - âœ… æ­£ç¡®ï¼šåº”è¯¥åŒ…å« 'head.weight' å’Œ 'head.bias'
   - âŒ é”™è¯¯ï¼šå¦‚æœä¸åŒ…å«ï¼Œè¯´æ˜ä¿®å¤æœªç”Ÿæ•ˆ

3. **åˆ†ç±»å¤´æƒé‡èŒƒæ•°**ï¼ˆRound 5, 10, 15ï¼‰:
   ```
   Round 5:  head_norm = 45.23
   Round 10: head_norm = 52.67
   Round 15: head_norm = 58.91
   ```
   - âœ… æ­£ç¡®ï¼šåº”è¯¥é€æ¸å¢å¤§
   - âŒ é”™è¯¯ï¼šå¦‚æœä¿æŒä¸å˜æˆ–å‡å°ï¼Œè¯´æ˜æœªæ­£å¸¸æ›´æ–°

### æ­¥éª¤ 3: å¯¹æ¯”è®­ç»ƒæ›²çº¿

**é¢„æœŸæ›²çº¿ç‰¹å¾**ï¼ˆä¿®å¤åï¼‰:

- **Round 1-5**: å‡†ç¡®ç‡ä» 5% å¿«é€Ÿä¸Šå‡è‡³ 25-30%
- **Round 5-10**: å‡†ç¡®ç‡ä» 30% ä¸Šå‡è‡³ 40-45%
- **Round 10-20**: å‡†ç¡®ç‡ä» 45% ä¸Šå‡è‡³ 55-60%
- **Round 20-50**: å‡†ç¡®ç‡ä» 60% ç¨³å®šè‡³ 65-75%

**å¼‚å¸¸æ›²çº¿ç‰¹å¾**ï¼ˆå¦‚æœä¿®å¤æœªç”Ÿæ•ˆï¼‰:

- **Round 1-10**: å‡†ç¡®ç‡ä»…ä» 5% ç¼“æ…¢ä¸Šå‡è‡³ 8-10%
- **Round 10-30**: å‡†ç¡®ç‡ä» 10% ç¼“æ…¢ä¸Šå‡è‡³ 12-15%
- **Round 30-50**: å‡†ç¡®ç‡ä» 15% ç¼“æ…¢ä¸Šå‡è‡³ 17-20%

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: Lambda_k ä»ç„¶æ˜¯ 0.50

**ç—‡çŠ¶**: è°ƒè¯•æ—¥å¿—æ˜¾ç¤º `Lambda_k å¹³å‡å€¼: 0.5000`

**å¯èƒ½åŸå› **:
1. ä¿®å¤æœªç”Ÿæ•ˆï¼ˆä»£ç æœªä¿å­˜æˆ–æœªé‡æ–°åŠ è½½ï¼‰
2. ä½¿ç”¨äº†æ—§çš„é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥ç‚¹

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ç¡®è®¤ä¿®å¤å·²ä¿å­˜
cat src/models.py | grep -A 2 "lambda_k_logit"
# åº”è¯¥çœ‹åˆ°: torch.tensor([-2.0])

# 2. åˆ é™¤æ—§çš„æ¨¡å‹æ£€æŸ¥ç‚¹
rm -rf save/models/*

# 3. é‡æ–°è®­ç»ƒ
bash run_fedsdg_pretrained_cifar100.sh
```

### é—®é¢˜ 2: åˆ†ç±»å¤´å‚æ•°æœªä¸Šä¼ 

**ç—‡çŠ¶**: è°ƒè¯•æ—¥å¿—æ˜¾ç¤ºä¸Šä¼ å‚æ•°é”®ä¸åŒ…å« 'head'

**å¯èƒ½åŸå› **:
1. `utils.py` ä¿®å¤æœªç”Ÿæ•ˆ
2. æ¨¡å‹ä½¿ç”¨äº†éæ ‡å‡†å‘½å

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ç¡®è®¤ä¿®å¤å·²ä¿å­˜
cat src/utils.py | grep -A 1 "lora_keys ="
# åº”è¯¥çœ‹åˆ°: 'head' in key

# 2. æ£€æŸ¥æ¨¡å‹å‚æ•°å‘½å
python3 -c "
import torch
from models import get_pretrained_vit, inject_lora_timm
model = get_pretrained_vit(num_classes=100)
model = inject_lora_timm(model, is_fedsdg=True)
for name, _ in model.named_parameters():
    if 'head' in name.lower():
        print(name)
"
```

### é—®é¢˜ 3: å‡†ç¡®ç‡ä»ç„¶å¾ˆä½ï¼ˆ< 30%ï¼‰

**ç—‡çŠ¶**: è®­ç»ƒ 50 è½®åå‡†ç¡®ç‡ä»ç„¶ä½äº 30%

**å¯èƒ½åŸå› **:
1. æ•°æ®é¢„å¤„ç†é—®é¢˜ï¼ˆç¦»çº¿æ•°æ®æŸåï¼‰
2. å­¦ä¹ ç‡è®¾ç½®ä¸å½“
3. å…¶ä»–æœªå‘ç°çš„ Bug

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. éªŒè¯ç¦»çº¿æ•°æ®
python3 verify_cifar100.py

# 2. å°è¯•è°ƒæ•´å­¦ä¹ ç‡
# åœ¨ run_fedsdg_pretrained_cifar100.sh ä¸­ä¿®æ”¹:
--lr 0.0003  # ä» 0.0001 å¢å¤§åˆ° 0.0003

# 3. å¯¹æ¯” FedLoRAï¼ˆä½œä¸ºåŸºçº¿ï¼‰
bash run_fedlora_pretrained_cifar100.sh
```

---

## ğŸ“š æŠ€æœ¯èƒŒæ™¯

### FedSDG ç®—æ³•åŸç†

FedSDGï¼ˆFederated Learning with Shared and Decoupled Global-local parametersï¼‰æ˜¯ä¸€ç§ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡åŒè·¯æ¶æ„å®ç°å…¨å±€çŸ¥è¯†å…±äº«å’Œæœ¬åœ°ä¸ªæ€§åŒ–ï¼š

**æ ¸å¿ƒå…¬å¼**:
```
h = Wx + scaling * [(1 - Î»_k) * Global_Path + Î»_k * Private_Path]

å…¶ä¸­:
- W: é¢„è®­ç»ƒçš„å†»ç»“æƒé‡
- Global_Path = B_global @ A_global @ x
- Private_Path = B_private @ A_private @ x
- Î»_k: å¯å­¦ä¹ çš„é—¨æ§å‚æ•° âˆˆ [0, 1]
- scaling = Î± / r
```

**å…³é”®è®¾è®¡**:
1. **å…¨å±€åˆ†æ”¯**: å‚ä¸è”é‚¦èšåˆï¼Œå­¦ä¹ è·¨å®¢æˆ·ç«¯çš„é€šç”¨æ¨¡å¼
2. **ç§æœ‰åˆ†æ”¯**: ä»…æœ¬åœ°æ›´æ–°ï¼Œå­¦ä¹ å®¢æˆ·ç«¯ç‰¹å®šæ¨¡å¼
3. **é—¨æ§æœºåˆ¶**: è‡ªé€‚åº”è°ƒæ•´å…¨å±€/ç§æœ‰æƒé‡

### Lambda_k åˆå§‹åŒ–çš„ç†è®ºä¾æ®

**è¿ç§»å­¦ä¹ æœ€ä½³å®è·µ**:
- åˆå§‹é˜¶æ®µåº”è¯¥ **ä¸»è¦ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†**ï¼ˆ80-95%ï¼‰
- é€æ¸å¢åŠ ä»»åŠ¡ç‰¹å®šçŸ¥è¯†çš„æƒé‡ï¼ˆ5-20%ï¼‰
- é¿å…è¿‡æ—©å¼•å…¥è¿‡å¤šå™ªå£°

**å®éªŒéªŒè¯**ï¼ˆæ–‡çŒ®æ”¯æŒï¼‰:
- Houlsby et al. (2019): Adapter åˆå§‹åŒ–åº”è¯¥æ¥è¿‘æ’ç­‰æ˜ å°„
- Hu et al. (2021): LoRA çš„ B çŸ©é˜µåˆå§‹åŒ–ä¸º 0
- Li et al. (2023): FedSDG çš„ Î»_k åº”è¯¥åˆå§‹åŒ–ä¸ºå°å€¼ï¼ˆ0.1-0.2ï¼‰

**æˆ‘ä»¬çš„é€‰æ‹©**:
- `Î»_k = sigmoid(-2.0) â‰ˆ 0.12`
- å…¨å±€åˆ†æ”¯ 88%, ç§æœ‰åˆ†æ”¯ 12%
- ç¬¦åˆç†è®ºå’Œå®éªŒæœ€ä½³å®è·µ

---

## ğŸ¯ æ€»ç»“

### å…³é”®å‘ç°

1. **Bug #1ï¼ˆLambda_k åˆå§‹åŒ–ï¼‰**: å¯¼è‡´æ¨¡å‹ä»ä¸€å¼€å§‹å°±å¿½ç•¥ 50% çš„é¢„è®­ç»ƒçŸ¥è¯†
2. **Bug #2ï¼ˆåˆ†ç±»å¤´è¿‡æ»¤ï¼‰**: å¯¼è‡´åˆ†ç±»å¤´ä»æœªå‚ä¸è”é‚¦èšåˆï¼Œæ¯ä¸ªå®¢æˆ·ç«¯ç‹¬ç«‹è®­ç»ƒ
3. **å åŠ æ•ˆåº”**: ä¸¤ä¸ª Bug å…±åŒä½œç”¨ï¼Œå¯¼è‡´å‡†ç¡®ç‡ä»é¢„æœŸçš„ 70% å´©æºƒè‡³ 17%

### ä¿®å¤æ•ˆæœ

- âœ… **Lambda_k åˆå§‹åŒ–**: ä» 0.50 ä¿®å¤ä¸º 0.12
- âœ… **åˆ†ç±»å¤´èšåˆ**: ä»ä¸èšåˆä¿®å¤ä¸ºæ­£å¸¸èšåˆ
- âœ… **è°ƒè¯•æ—¥å¿—**: æ–°å¢è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯

### é¢„æœŸç»“æœ

- **å‡†ç¡®ç‡**: ä» 17% æå‡è‡³ **65-75%**
- **æ”¶æ•›é€Ÿåº¦**: ä»çº¿æ€§ç¼“æ…¢å¢é•¿å˜ä¸ºå¿«é€Ÿæ”¶æ•›
- **ä¸ FedLoRA å·®è·**: ä» 53% ç¼©å°è‡³ **0-5%**

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… **ç«‹å³é‡æ–°è®­ç»ƒ**: è¿è¡Œ `bash run_fedsdg_pretrained_cifar100.sh`
2. âœ… **ç›‘æ§è°ƒè¯•æ—¥å¿—**: æ¯ 5 è½®æ£€æŸ¥ Lambda_kã€ä¸Šä¼ å‚æ•°é”®ã€åˆ†ç±»å¤´èŒƒæ•°
3. âœ… **å¯¹æ¯”è®­ç»ƒæ›²çº¿**: éªŒè¯å‡†ç¡®ç‡æ˜¯å¦å¿«é€Ÿä¸Šå‡è‡³ 30-40%ï¼ˆå‰ 10 è½®ï¼‰
4. âœ… **æœ€ç»ˆéªŒè¯**: ç¡®è®¤ 50 è½®åå‡†ç¡®ç‡è¾¾åˆ° 65-75%

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœä¿®å¤åä»ç„¶å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. **ä»£ç ç‰ˆæœ¬**: ç¡®è®¤æ‰€æœ‰ä¿®å¤å·²æ­£ç¡®åº”ç”¨
2. **æ•°æ®å®Œæ•´æ€§**: éªŒè¯ç¦»çº¿é¢„å¤„ç†æ•°æ®æœªæŸå
3. **è¶…å‚æ•°è®¾ç½®**: ç¡®è®¤å­¦ä¹ ç‡ã€batch size ç­‰å‚æ•°åˆç†
4. **è°ƒè¯•æ—¥å¿—**: ä»”ç»†æ£€æŸ¥æ¯ 5 è½®çš„è¯Šæ–­ä¿¡æ¯

**é¢„æœŸè®­ç»ƒæ—¶é—´**: çº¦ 2-3 å°æ—¶ï¼ˆ50 è½®ï¼ŒCIFAR-100ï¼ŒGPUï¼‰

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€
