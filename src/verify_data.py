#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹æ•°æ®éªŒè¯è„šæœ¬
åŠŸèƒ½ï¼šå…¨é¢æ£€æµ‹é¢„å¤„ç†åçš„ CIFAR-10 æ•°æ®æ˜¯å¦æ­£ç¡®
åŒ…æ‹¬ï¼šæ–‡ä»¶å®Œæ•´æ€§ã€æ•°æ®å½¢çŠ¶ã€æ•°å€¼èŒƒå›´ã€æ ‡ç­¾åˆ†å¸ƒã€æ•°æ®ä¸€è‡´æ€§ç­‰
"""

import os
import numpy as np
import argparse
from tqdm import tqdm


def verify_preprocessed_data(image_size=224, output_root='../data/preprocessed/', 
                            check_samples=10, verbose=True):
    """
    å…¨é¢éªŒè¯é¢„å¤„ç†æ•°æ®çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
    
    å‚æ•°:
        image_size: å›¾åƒå°ºå¯¸
        output_root: é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•
        check_samples: éšæœºæ£€æŸ¥çš„æ ·æœ¬æ•°é‡
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    è¿”å›:
        bool: éªŒè¯æ˜¯å¦é€šè¿‡
    """
    print("\n" + "="*80)
    print("CIFAR-10 é¢„å¤„ç†æ•°æ®éªŒè¯å·¥å…·".center(80))
    print("="*80 + "\n")
    
    output_dir = os.path.join(output_root, f'cifar10_{image_size}x{image_size}')
    
    if not os.path.exists(output_dir):
        print(f"âŒ é”™è¯¯ï¼šæ•°æ®ç›®å½•ä¸å­˜åœ¨: {output_dir}")
        print(f"   è¯·å…ˆè¿è¡Œé¢„å¤„ç†è„šæœ¬: python preprocess_data.py --image_size {image_size}")
        return False
    
    print(f"ğŸ“ æ•°æ®ç›®å½•: {output_dir}\n")
    
    all_passed = True
    
    for split in ['train', 'test']:
        print(f"\n{'='*80}")
        print(f"éªŒè¯ {split.upper()} é›†".center(80))
        print(f"{'='*80}\n")
        
        images_path = os.path.join(output_dir, f'{split}_images.npy')
        labels_path = os.path.join(output_dir, f'{split}_labels.npy')
        
        # ========== 1. æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥ ==========
        print("ã€1ã€‘æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥")
        if not os.path.exists(images_path):
            print(f"  âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {images_path}")
            all_passed = False
            continue
        else:
            print(f"  âœ“ å›¾åƒæ–‡ä»¶å­˜åœ¨: {images_path}")
        
        if not os.path.exists(labels_path):
            print(f"  âŒ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {labels_path}")
            all_passed = False
            continue
        else:
            print(f"  âœ“ æ ‡ç­¾æ–‡ä»¶å­˜åœ¨: {labels_path}")
        
        # æ–‡ä»¶å¤§å°
        images_size_mb = os.path.getsize(images_path) / (1024 ** 2)
        labels_size_mb = os.path.getsize(labels_path) / (1024 ** 2)
        print(f"  âœ“ å›¾åƒæ–‡ä»¶å¤§å°: {images_size_mb:.2f} MB")
        print(f"  âœ“ æ ‡ç­¾æ–‡ä»¶å¤§å°: {labels_size_mb:.2f} MB")
        
        # ========== 2. æ•°æ®åŠ è½½æ£€æŸ¥ ==========
        print("\nã€2ã€‘æ•°æ®åŠ è½½æ£€æŸ¥")
        try:
            # å›¾åƒæ–‡ä»¶æ˜¯ memmap æ ¼å¼ï¼Œéœ€è¦çŸ¥é“å½¢çŠ¶å’Œæ•°æ®ç±»å‹
            expected_samples = 50000 if split == 'train' else 10000
            
            # å°è¯•åŠ è½½å›¾åƒ memmap
            images = np.memmap(
                images_path,
                dtype='float32',
                mode='r',
                shape=(expected_samples, 3, image_size, image_size)
            )
            
            # æ ‡ç­¾æ–‡ä»¶æ˜¯æ ‡å‡† numpy æ•°ç»„
            labels = np.load(labels_path, allow_pickle=True)
            
            print(f"  âœ“ æ•°æ®åŠ è½½æˆåŠŸï¼ˆå›¾åƒ: memmap, æ ‡ç­¾: numpy arrayï¼‰")
        except Exception as e:
            print(f"  âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            all_passed = False
            continue
        
        # ========== 3. æ•°æ®å½¢çŠ¶æ£€æŸ¥ ==========
        print("\nã€3ã€‘æ•°æ®å½¢çŠ¶æ£€æŸ¥")
        expected_samples = 50000 if split == 'train' else 10000
        expected_shape = (expected_samples, 3, image_size, image_size)
        
        if images.shape == expected_shape:
            print(f"  âœ“ å›¾åƒå½¢çŠ¶æ­£ç¡®: {images.shape}")
        else:
            print(f"  âŒ å›¾åƒå½¢çŠ¶é”™è¯¯: {images.shape}, æœŸæœ›: {expected_shape}")
            all_passed = False
        
        if labels.shape == (expected_samples,):
            print(f"  âœ“ æ ‡ç­¾å½¢çŠ¶æ­£ç¡®: {labels.shape}")
        else:
            print(f"  âŒ æ ‡ç­¾å½¢çŠ¶é”™è¯¯: {labels.shape}, æœŸæœ›: ({expected_samples},)")
            all_passed = False
        
        # ========== 4. æ•°æ®ç±»å‹æ£€æŸ¥ ==========
        print("\nã€4ã€‘æ•°æ®ç±»å‹æ£€æŸ¥")
        if images.dtype == np.float32:
            print(f"  âœ“ å›¾åƒæ•°æ®ç±»å‹æ­£ç¡®: {images.dtype}")
        else:
            print(f"  âŒ å›¾åƒæ•°æ®ç±»å‹é”™è¯¯: {images.dtype}, æœŸæœ›: float32")
            all_passed = False
        
        if labels.dtype == np.int64:
            print(f"  âœ“ æ ‡ç­¾æ•°æ®ç±»å‹æ­£ç¡®: {labels.dtype}")
        else:
            print(f"  âš  æ ‡ç­¾æ•°æ®ç±»å‹: {labels.dtype} (æœŸæœ›: int64, ä½†å¯èƒ½å…¼å®¹)")
        
        # ========== 5. æ•°æ®å€¼èŒƒå›´æ£€æŸ¥ ==========
        print("\nã€5ã€‘æ•°æ®å€¼èŒƒå›´æ£€æŸ¥")
        
        if len(images) == 0:
            print(f"  âŒ å›¾åƒæ•°æ®ä¸ºç©º")
            all_passed = False
        else:
            # æ£€æŸ¥å¤šä¸ªæ ·æœ¬çš„å€¼èŒƒå›´
            sample_indices = np.random.choice(len(images), min(check_samples, len(images)), replace=False)
            min_vals = []
            max_vals = []
            
            for idx in sample_indices:
                min_vals.append(images[idx].min())
                max_vals.append(images[idx].max())
            
            overall_min = min(min_vals)
            overall_max = max(max_vals)
            
            # å›¾åƒåº”è¯¥åœ¨ [0, 1] èŒƒå›´å†…ï¼ˆç»è¿‡ ToTensor å½’ä¸€åŒ–ï¼‰
            if 0.0 <= overall_min and overall_max <= 1.0:
                print(f"  âœ“ å›¾åƒå€¼èŒƒå›´æ­£ç¡®: [{overall_min:.4f}, {overall_max:.4f}] (æ£€æŸ¥äº† {len(sample_indices)} ä¸ªæ ·æœ¬)")
            else:
                print(f"  âŒ å›¾åƒå€¼èŒƒå›´å¼‚å¸¸: [{overall_min:.4f}, {overall_max:.4f}], æœŸæœ›: [0.0, 1.0]")
                all_passed = False
            
            if verbose:
                print(f"     æ ·æœ¬å€¼èŒƒå›´è¯¦æƒ…:")
                for i, idx in enumerate(sample_indices[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"       æ ·æœ¬ {idx}: [{min_vals[i]:.4f}, {max_vals[i]:.4f}]")
        
        if len(labels) == 0:
            print(f"  âŒ æ ‡ç­¾æ•°æ®ä¸ºç©º")
            all_passed = False
        else:
            label_min = labels.min()
            label_max = labels.max()
            
            # CIFAR-10 æ ‡ç­¾åº”è¯¥åœ¨ [0, 9] èŒƒå›´å†…
            if label_min == 0 and label_max == 9:
                print(f"  âœ“ æ ‡ç­¾å€¼èŒƒå›´æ­£ç¡®: [{label_min}, {label_max}]")
            else:
                print(f"  âŒ æ ‡ç­¾å€¼èŒƒå›´é”™è¯¯: [{label_min}, {label_max}], æœŸæœ›: [0, 9]")
                all_passed = False
        
        # ========== 6. æ ‡ç­¾åˆ†å¸ƒæ£€æŸ¥ ==========
        print("\nã€6ã€‘æ ‡ç­¾åˆ†å¸ƒæ£€æŸ¥")
        if len(labels) > 0:
            label_counts = np.bincount(labels)
            print(f"  âœ“ æ ‡ç­¾åˆ†å¸ƒ:")
            
            class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                          'dog', 'frog', 'horse', 'ship', 'truck']
            
            for i, count in enumerate(label_counts):
                percentage = count / len(labels) * 100
                print(f"     ç±»åˆ« {i} ({class_names[i]:>10s}): {count:>5d} æ ·æœ¬ ({percentage:>5.2f}%)")
            
            # æ£€æŸ¥ç±»åˆ«å¹³è¡¡æ€§ï¼ˆCIFAR-10 åº”è¯¥æ˜¯å¹³è¡¡çš„ï¼‰
            expected_count = len(labels) // 10
            tolerance = expected_count * 0.1  # å…è®¸ 10% çš„åå·®
            
            is_balanced = all(abs(count - expected_count) <= tolerance for count in label_counts)
            if is_balanced:
                print(f"  âœ“ ç±»åˆ«åˆ†å¸ƒå¹³è¡¡ï¼ˆæ¯ç±»çº¦ {expected_count} ä¸ªæ ·æœ¬ï¼‰")
            else:
                print(f"  âš  ç±»åˆ«åˆ†å¸ƒä¸å®Œå…¨å¹³è¡¡ï¼ˆæœŸæœ›æ¯ç±»çº¦ {expected_count} ä¸ªæ ·æœ¬ï¼‰")
        
        # ========== 7. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ ==========
        print("\nã€7ã€‘æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        if len(images) == len(labels):
            print(f"  âœ“ å›¾åƒå’Œæ ‡ç­¾æ•°é‡ä¸€è‡´: {len(images)} ä¸ªæ ·æœ¬")
        else:
            print(f"  âŒ å›¾åƒå’Œæ ‡ç­¾æ•°é‡ä¸ä¸€è‡´: å›¾åƒ {len(images)}, æ ‡ç­¾ {len(labels)}")
            all_passed = False
        
        # ========== 8. éšæœºæ ·æœ¬æŠ½æŸ¥ ==========
        print("\nã€8ã€‘éšæœºæ ·æœ¬æŠ½æŸ¥")
        if len(images) > 0 and len(labels) > 0:
            print(f"  æ­£åœ¨æ£€æŸ¥ {check_samples} ä¸ªéšæœºæ ·æœ¬...")
            sample_indices = np.random.choice(len(images), min(check_samples, len(images)), replace=False)
            
            issues = []
            for idx in tqdm(sample_indices, desc="  æ£€æŸ¥æ ·æœ¬", leave=False):
                img = images[idx]
                label = labels[idx]
                
                # æ£€æŸ¥å›¾åƒå½¢çŠ¶
                if img.shape != (3, image_size, image_size):
                    issues.append(f"æ ·æœ¬ {idx}: å½¢çŠ¶é”™è¯¯ {img.shape}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ NaN æˆ– Inf
                if np.isnan(img).any():
                    issues.append(f"æ ·æœ¬ {idx}: åŒ…å« NaN")
                if np.isinf(img).any():
                    issues.append(f"æ ·æœ¬ {idx}: åŒ…å« Inf")
                
                # æ£€æŸ¥æ ‡ç­¾èŒƒå›´
                if not (0 <= label <= 9):
                    issues.append(f"æ ·æœ¬ {idx}: æ ‡ç­¾è¶…å‡ºèŒƒå›´ {label}")
            
            if len(issues) == 0:
                print(f"  âœ“ æ‰€æœ‰æŠ½æŸ¥æ ·æœ¬æ­£å¸¸")
            else:
                print(f"  âŒ å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
                for issue in issues[:10]:  # æœ€å¤šæ˜¾ç¤º 10 ä¸ª
                    print(f"     - {issue}")
                all_passed = False
        
        print(f"\n{'-'*80}")
    
    # ========== 9. å…ƒæ•°æ®æ£€æŸ¥ ==========
    print(f"\n{'='*80}")
    print("ã€9ã€‘å…ƒæ•°æ®æ£€æŸ¥".center(80))
    print(f"{'='*80}\n")
    
    metadata_path = os.path.join(output_dir, 'metadata.txt')
    if os.path.exists(metadata_path):
        print(f"âœ“ å…ƒæ•°æ®æ–‡ä»¶å­˜åœ¨: {metadata_path}")
        print(f"\nå…ƒæ•°æ®å†…å®¹:")
        with open(metadata_path, 'r') as f:
            for line in f:
                print(f"  {line.rstrip()}")
    else:
        print(f"âš  å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_path}")
    
    # ========== æœ€ç»ˆç»“æœ ==========
    print(f"\n{'='*80}")
    if all_passed:
        print("âœ… éªŒè¯é€šè¿‡ï¼æ•°æ®å®Œæ•´æ€§å’Œæ­£ç¡®æ€§æ­£å¸¸ã€‚".center(80))
    else:
        print("âŒ éªŒè¯å¤±è´¥ï¼å‘ç°æ•°æ®é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚".center(80))
    print(f"{'='*80}\n")
    
    return all_passed


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='CIFAR-10 é¢„å¤„ç†æ•°æ®éªŒè¯å·¥å…·')
    parser.add_argument('--image_size', type=int, default=224,
                        help='å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤ 224ï¼‰')
    parser.add_argument('--output_root', type=str, default='../data/preprocessed/',
                        help='é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--check_samples', type=int, default=10,
                        help='éšæœºæ£€æŸ¥çš„æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰')
    parser.add_argument('--verbose', action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # è¿è¡ŒéªŒè¯
    passed = verify_preprocessed_data(
        image_size=args.image_size,
        output_root=args.output_root,
        check_samples=args.check_samples,
        verbose=args.verbose
    )
    
    # è¿”å›é€€å‡ºç 
    exit(0 if passed else 1)
